{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_regression, RFE, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection for penguin classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   animal_id species  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "0          1  Adelie            39.1           18.7              181.0   \n",
      "1          2  Adelie            39.5           17.4              186.0   \n",
      "2          3  Adelie            40.3           18.0              195.0   \n",
      "3          4  Adelie            36.7           19.3              193.0   \n",
      "4          5  Adelie            39.3           20.6              190.0   \n",
      "\n",
      "   body_mass_g     sex  island_id  \n",
      "0       3750.0    Male          1  \n",
      "1       3800.0  Female          1  \n",
      "2       3250.0  Female          1  \n",
      "3       3450.0  Female          1  \n",
      "4       3650.0    Male          1  \n"
     ]
    }
   ],
   "source": [
    "# Connect to the data base\n",
    "conn = sqlite3.connect(\"penguins.db\")\n",
    "\n",
    "# Read the data from the penguins table\n",
    "df = pd.read_sql(\"SELECT * FROM penguins\", conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove irrelevant columns \n",
    "# 'animal_id' is an unique indicator, 'sex' can be relevant but not for now\n",
    "df = df.drop(columns=[\"animal_id\", \"sex\"]) \n",
    "\n",
    "# Split features and target variable\n",
    "X = df.drop(columns=[\"species\"])  # Features\n",
    "y = df[\"species\"].astype(\"category\").cat.codes  # Convert categorical target to numerical\n",
    "\n",
    "#Split dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #test_size 0,2 = 20% of the data is testdata, random_state=42, making sure we get the same split every time we run the code, so the results are even.\n",
    "\n",
    "#Normalize the features\n",
    "scaler = StandardScaler() #so the average is 0 and the std is 1, this is important because some of the features has a lot bigger value than the others\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter method (mutual information)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information Scores (Filter Method):\n",
      "bill_length_mm       0.743185\n",
      "flipper_length_mm    0.657526\n",
      "bill_depth_mm        0.617839\n",
      "body_mass_g          0.597146\n",
      "island_id            0.530223\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(score_func=mutual_info_classif, k='all')  # Evaluate all features\n",
    "# 'SelectKBest' --> function that picks K best features, k=all, because we evaluate all but doesnt choose yet\n",
    "selector.fit(X_train_scaled, y_train) # the models learns how much information each feature gives about target variable\n",
    "\n",
    "# High MI-score --> The feature helps alot to predict the speices \n",
    "# Low MI-score --> the features doesnt almost help with the prediction\n",
    "\n",
    "# Mutual Information Scores\n",
    "mi_scores = pd.Series(selector.scores_, index=X.columns) #saves the score for each feature in a table\n",
    "# selector.scores_ --> list over MI-scores for each feature\n",
    "# index=X.columns --> names all the rows with feature names \n",
    "\n",
    "mi_scores.sort_values(ascending=False, inplace=True) #sort features from most important to less important\n",
    "# ascending=False --> sort from high to low\n",
    "#inplace=True --> savnes the changes in mi_scores\n",
    "\n",
    "print(\"Mutual Information Scores (Filter Method):\")\n",
    "print(mi_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EMBEDDED METHOD (Random Forest Feature Importance)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Feature Importance (Embedded Method):\n",
      "bill_length_mm       0.347782\n",
      "flipper_length_mm    0.261785\n",
      "bill_depth_mm        0.176183\n",
      "island_id            0.145641\n",
      "body_mass_g          0.068610\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42) #Create a Random Forest-model with 100 trees (n_estimators=100)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Feature importance fra Random Forest\n",
    "feature_importance = pd.Series(model.feature_importances_, index=X.columns) #Makes a list about the most important features according Random Forest\n",
    "feature_importance.sort_values(ascending=False, inplace=True) #Makes a table where each feature gets a score\n",
    "\n",
    "print(\"Random Forest Feature Importance (Embedded Method):\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PERMUTATION IMPORTANCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation Importance Scores:\n",
      "bill_length_mm       0.157303\n",
      "island_id            0.117603\n",
      "bill_depth_mm        0.083146\n",
      "flipper_length_mm    0.070412\n",
      "body_mass_g          0.004494\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Tests how important each feature is for the models precision\n",
    "#The model shuffles one feature at a time to see how much the models accuracy falls\n",
    "# If a feature isnt important, the shuffle will not affect the models performance\n",
    "# If a feature is important, the accuracy will be worse\n",
    "perm_importance = permutation_importance(model, X_test_scaled, y_test, scoring=\"accuracy\") \n",
    "\n",
    "# Feature importance fra Permutation Importance\n",
    "perm_scores = pd.Series(perm_importance.importances_mean, index=X.columns)\n",
    "perm_scores.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "print(\"Permutation Importance Scores:\")\n",
    "print(perm_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WRAPPER METHOD (RFE - Recursive Feature Elimination)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE Features: ['bill_length_mm', 'bill_depth_mm', 'body_mass_g']\n"
     ]
    }
   ],
   "source": [
    "rfe_model = LogisticRegression() #Used to evaluate the importance of the feature\n",
    "rfe = RFE(estimator=rfe_model, n_features_to_select=3)  # Picking top 3 features\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Få RFE feature ranking og sorter de bedste features\n",
    "rfe_features = X.columns[rfe.support_].tolist()\n",
    "print(\"RFE Features:\", rfe_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection Results\n",
      "          Feature Mutual Info RFE Random Forest Permutation  Keep/Remove?\n",
      "   bill_length_mm           ✅   ✅             ✅           ✅        Keep ✅\n",
      "    bill_depth_mm           ✅   ✅             ✅           ✅        Keep ✅\n",
      "flipper_length_mm           ✅   ❌             ✅           ❌        Keep ✅\n",
      "      body_mass_g           ❌   ✅             ❌           ❌      Remove ❌\n",
      "        island_id           ❌   ❌             ❌           ✅      Remove ❌\n"
     ]
    }
   ],
   "source": [
    "# Create a list over all features\n",
    "features = X.columns.tolist()\n",
    "\n",
    "# A function that marks if a feature is in top 3 for each method \n",
    "def check_top_features(feature, method_top_features):\n",
    "    return \"✅\" if feature in method_top_features else \"❌\"\n",
    "\n",
    "# Build a dynamic table \n",
    "feature_table = pd.DataFrame({\n",
    "    \"Feature\": features,\n",
    "    \"Mutual Info\": [check_top_features(f, mi_scores.head(3).index.tolist()) for f in features],\n",
    "    \"RFE\": [check_top_features(f, rfe_features) for f in features],\n",
    "    \"Random Forest\": [check_top_features(f, feature_importance.head(3).index.tolist()) for f in features],\n",
    "    \"Permutation\": [check_top_features(f, perm_scores.head(3).index.tolist()) for f in features]\n",
    "})\n",
    "\n",
    "# Decide whether to keep or remove a feature (If it is important in at least 2 methods, keep it)\n",
    "feature_table[\" Keep/Remove?\"] = feature_table[[\"Mutual Info\", \"RFE\", \"Random Forest\", \"Permutation\"]].apply(\n",
    "    lambda row: \"Keep ✅\" if list(row).count(\"✅\") >= 2 else \"Remove ❌\", axis=1\n",
    ")\n",
    "\n",
    "# Print the table\n",
    "print(\"Feature Selection Results\")\n",
    "print(feature_table.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final features\n",
      "['bill_length_mm', 'flipper_length_mm', 'bill_depth_mm']\n"
     ]
    }
   ],
   "source": [
    "# We remove body_mass_g and island_id since it is only important in one method\n",
    "\n",
    "final_features = [\"bill_length_mm\", \"flipper_length_mm\", \"bill_depth_mm\"]\n",
    "print(\"Final features\")\n",
    "print(final_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Only using the final features \n",
    "X_train_final = X_train[final_features]\n",
    "X_test_final = X_test[final_features]\n",
    "\n",
    "# Train on Logistic Regression model, because we have classification problem\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_final, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test_final)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Final Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: 0.99 ± 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(model, X_train_final, y_train, cv=5)\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.2f} ± {cv_scores.std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'penguin_classifier.joblib'\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Save the model\n",
    "dump(model, \"penguin_classifier.joblib\")\n",
    "print(\"Model saved as 'penguin_classifier.joblib'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
